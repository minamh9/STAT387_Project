---
title: "stat387"
author: "Mina Mehdinia, Tim Luo, Will McIntosh"
date: "2023-03-01"
output: html_document
---
# Setup
 
```{r setup, include = F}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)  # Suite of packages incl: dplyr, ggplot2, tidyr, etc.
library(MASS)       # LDA, QDA, OLS, Ridge Regression, Box-Cox, stepAIC, etc.
library(ROCR)       # Precision/Recall/Sens./Spec./ performance plot
library(class)      # KNN, SOM, LVQ
library(e1071)      # Naive Bayesian Classifier, SVM, GKNN, ICA, LCA
library(boot)       # LOOCV, Bootstrap
library(caret)      # Classification/Regression Training
library(randomForest) # Random forest
library(naivebayes) 
library(corrplot)
library(fastDummies)
source("Stat387-Proj-HelperFunctions.R")
# rm(list=ls())
```

```{r function}
Plot.Correlation <- function(df, column.name, main.title="") {
  
  # create a contingency table
  table_df <- table(df[,column.name], df$Default)
  # print(as.data.frame(table_df))
  
  # plot the heatmap
  ggplot(data = as.data.frame(table_df), 
         aes(x = Var1, y = Var2, fill = Freq)) +
    geom_tile() +
    scale_fill_gradient(low = "white", high = "red") +
    scale_x_discrete(labels = c("No", "Yes")) +
    scale_y_discrete(labels = c("Yes", "No")) +
    theme_minimal() +
    theme(panel.border = element_rect(color = "black", fill = NA,
                                      linewidth = .5)) +
    labs(x = main.title, y = "Default?",
         title = paste("Correlation Heatmap for",
                       as.character(column.name)))
}

# Plot.Correlation(german.dummy, "checkingA14",
#                  as.character(name.dict["A14"]))
```

```{r read}
german <- read.csv("germancredit.csv", header=T) |> 
  rename(checking = checkingstatus1) |> 
  mutate(installment = ifelse(installment == 1, "< 20%",
                              ifelse(installment == 2, "20 - 25%",
                                     ifelse(installment == 3, "25 - 35%",
                                            "> 35%"))))
# |> 
#   mutate(status_fix = ifelse(status  %in% c("A91", "A94"), "A96", status),
#          .after = status)

german.num = german |> select_if(is.numeric)

german.cat = german |> select_if(is.character)

name.dict[["A11"]]
as.list(name.dict)[["A11"]]

german.desc = german.cat |> 
  mutate_at(vars(-c("installment")), ~as.character(name.dict[.])) |> 
  cbind(german.num)

german.desc

german.dummy = GetDummies(german)

german.dummy.drop = GetDummies(german, TRUE)
```

# Exploratory

\newpage

```{r summary}
set.seed(123)

summary(german.cat)
summary(german.num)
# names(german.num)
```

```{r RFE}
RFE(german.dummy, 10)
RFE(german.dummy.drop, 10)
```


```{r fullcorrplot}
cor(german.num) |> corrplot(method = "number", type = "lower", 
                        tl.col = "grey20", number.cex = 1, bg = "grey30",
                        title = "Correlation Plot of Numeric Predictors",
                        mar = c(0,0,2,0), diag = FALSE)
```

```{r logistic}
german.log = glm(Default ~ ., german, family = "binomial")
german.log.sum = summary(german.log)
german.log.names = data.frame(german.log.sum$coef[german.log.sum$coef[,4] <= .05, 4]) |> row.names()

german.log.sig = glm(Default ~ checking + duration + history + purpose + 
                       amount + savings + installment + otherplans,
                     german, family = "binomial")
summary(german.log.sig)
```


```{r corr}
# german.log.names
# Plot.Correlation(german.dummy, "checkingA14", "Checking: No checking account")
for(name in german.log.names) {
  if(grepl(".A.", name)) {
    label = paste0(name.dict[str_extract(name, "A[0-9]+")] |> as.character(), "?")
  }
  else {
    label = paste0(name |> str_to_title(), "?")
  }
  print(Plot.Correlation(german.dummy, name, label))
}
```

# One-Hot Encoding

Below I am making dummy variables (or one-hot encodings) of the categorical variables (WMM - 3/2/23).

```{r}
dummy <- dummyVars(" ~ .", data=german)
newgerman <- data.frame(predict(dummy, newdata = german))
head(newgerman)
```

# Value Counts For Each Class Type

```{r}
Count.Plot <- function(data, column.name, main.title="", xlab = "", a = 0, h = .5) {  
  german.0.default <- data[data$Default == 0, ]
  german.1.default <- data[data$Default == 1, ]
  
  checkingstatus.counts.0 <- table(german.0.default[column.name])
  checkingstatus.counts.1 <- table(german.1.default[column.name])
  
  counts.df.0 <- as.data.frame(checkingstatus.counts.0)
  counts.df.1 <- as.data.frame(checkingstatus.counts.1)
  
  colnames(counts.df.0) <- c(column.name, "count")
  colnames(counts.df.1) <- c(column.name, "count")
  
  counts.df.0 <- counts.df.0 %>% mutate(class = 0)
  counts.df.1 <- counts.df.1 %>% mutate(class = 1)
  
  # Combine the two data frames
  combined_df <- rbind(counts.df.0, counts.df.1)
  
  # Create the plot
  ggplot(combined_df, 
         aes(x = combined_df[,column.name], y = count, 
             fill = as.factor(class))) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = xlab, y = "Count", fill = "Default?",
         title = main.title) +
    scale_fill_manual(labels = c("No", "Yes"),
                      values = c("#00BFC4", "#F8766D")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle=a, hjust=h),
          panel.background = element_rect(color = "black",
                                          fill = NA,
                                          linewidth = .5))
}
```

## Plotting Checking Status Count Per Class

```{r}
Count.Plot(german.desc, "checking", "Default vs Checking Status", "Checking Status")
```

## Plotting History Count Per Class

```{r}
Count.Plot2 <- function(data, column.name, main.title="", xlab = "", a = 0, h = .5) {  
  german.0.default <- data[data$Default == 0, ]
  german.1.default <- data[data$Default == 1, ]
  
  checkingstatus.counts.0 <- table(german.0.default[column.name])
  checkingstatus.counts.1 <- table(german.1.default[column.name])
  
  counts.df.0 <- as.data.frame(checkingstatus.counts.0)
  counts.df.1 <- as.data.frame(checkingstatus.counts.1)

  colnames(counts.df.0) <- c(column.name, "count")
  colnames(counts.df.1) <- c(column.name, "count")
  
  counts.df.0 <- counts.df.0 %>% mutate(class = 0)
  counts.df.1 <- counts.df.1 %>% mutate(class = 1)

  # Combine the two data frames
  combined_df <- rbind(counts.df.0, counts.df.1)

  # Create the plot
  ggplot(combined_df, 
         aes(x = fct_inorder(.data[[column.name]]), y = count, 
             fill = as.factor(class))) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = xlab, y = "Count", fill = "Default?",
         title = main.title) +
    scale_fill_manual(labels = c("No", "Yes"),
                      values = c("#00BFC4", "#F8766D")) +
    scale_x_discrete(labels = function(x) str_wrap(x, width=20)) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle=a, hjust=h),
          panel.background = element_rect(color = "black",
                                          fill = NA,
                                          linewidth = .5))
}
Count.Plot2(german.desc, "history", "Default vs Credit History", "Credit History")
```

## Plotting Purpose Count Per Class

```{r}
Count.Plot(german.desc, "purpose", "Default vs Purpose of Loan", "Purpose of Loan", 90, 1)
```

## Plotting Savings Count Per Class

```{r}


Count.Plot2(german.desc, "savings", "Default vs Savings Account", "Savings Account")
```

## Plotting Employ Count Per Class

```{r}
Count.Plot(german, "employ")
```

```{r}
Count.Plot(german.desc, "others")
```


```{r}


Count.Plot2(german.desc, "installment", "Default vs Installment Percentage", "Installment Percentage")
```

```{r}
Count.Plot(german.desc, "housing", "Default vs Residential Status", "Residential Status")

```


# Displaying Duration For Each Class

```{r}
Density.Plot <- function(data, column.name) {
  
  # Create subsets of the dataframe based on the binary class
  df_default0 <- data[data[["Default"]] == 0,]
  df_default1 <- data[data[["Default"]] == 1,]
  
  # Plot the two density plots on the same plot
  ggplot() +
    geom_density(data = df_default0, aes(x = df_default0[,column.name], fill = "Default 0"), alpha = 0.5) +
    geom_density(data = df_default1, aes(x = df_default1[,column.name], fill = "Default 1"), alpha = 0.5) +
    labs(title = paste("Distribution of", column.name, "by Default"),
         x = column.name,
         y = "Density") +
    scale_fill_manual(values = c("#F8766D", "#00BFC4"), name = "Default") +
    theme_minimal()
}
```

# Displaying Amount For Each Class

```{r}
Density.Plot(german, "duration")
```

```{r}
Density.Plot(german, "amount")
```

```{r}
Density.Plot(german, "installment")
```

```{r}
Density.Plot(german, "residence")
```

```{r}
Density.Plot(german, "age")
```

```{r}
Density.Plot(german, "cards")
```

```{r}
Density.Plot(german, "liable")
```


# One-Hot Encoding

Below I am making dummy variables (or one-hot encodings) of the categorical variables.

```{r}
dummy <- dummyVars(" ~ .", data=german)
dummy.german <- data.frame(predict(dummy, newdata = german)) 
head(dummy.german)
```

# RFE

```{r}
RFE <- function(data, num.features=4) {
  # Define the predictor and response variables
  train.X <- data[, !(names(data) %in% c("Default"))]
  train.Y <- as.factor(data[, "Default"])
  
  # Define the control parameters for feature selection
  ctrl <- rfeControl(functions = rfFuncs,
                     method = "cv",
                     number = 10)
  
  # Perform recursive feature elimination using the random forest algorithm
  rf_rfe <- rfe(train.X, train.Y, sizes = c(1:num.features), rfeControl = ctrl)
  
  # Print the results
  print(rf_rfe)
  
  # Plot the results
  plot(rf_rfe, type = c("g", "o"))
}
```

## Running RFE on Dummy-Variabled German Data

```{r}
RFE(german)
```

## Running RFE on Dummy-Variabled German Data

```{r}
RFE(dummy.german)
```

## Running RFE on Dummy-Variabled German Data with Only 2 Variables

```{r}
RFE(dummy.german, num.features=2)
```

## Running RFE on Dummy-Variabled German Data with 10 Variables

```{r}
RFE(dummy.german, num.features=10)
```

## Running RFE on Dummy-Variabled German Data with 20 Variables

```{r}
RFE(dummy.german, num.features=20)
```

# Running PCA Dimensionality Reduction

The first 26 features are statistically significant since they're ab

```{r}
# Standardize the data
dummy.german_std <- scale(dummy.german)

# Perform PCA
german.pca <- prcomp(dummy.german_std, center = TRUE, scale. = TRUE)

# Interpret the results
summary(german.pca)
```

```{r}
# Extract the standard deviations of each principal component
sd <- summary(german.pca)$sdev

# Plot the standard deviations as a line plot
plot(sd, type = "b", xlab = "Principal Component", ylab = "Standard Deviation")
```

# Passing PCA Results in NB

```{r}
# Extract the principal component scores
pc_scores <- predict(german.pca, dummy.german_std)

# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_index <- sample(nrow(dummy.german_std), nrow(dummy.german_std) * 0.7) # 70% for training
train_data <- pc_scores[train_index, ]
train_label <- as.factor(dummy.german_std[train_index,"Default"])
test_data <- pc_scores[-train_index, ]
test_label <- as.factor(dummy.german_std[-train_index,"Default"])

# Train the NaÃ¯ve Bayes classifier using the training data
model <- naive_bayes(train_data, train_label)

# Predict the test data using the trained model
model.preds <- predict(model, test_data)

# Evaluate the performance of the model
confusionMatrix(model.preds, test_label)
```

# Passing PCA Results in KNN

```{r}
# Extract the principal component scores
pc_scores <- predict(german.pca, dummy.german_std)

# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_index <- sample(nrow(dummy.german_std), nrow(dummy.german_std) * 0.7) # 70% for training
train_data <- pc_scores[train_index, ]
train_label <- as.factor(dummy.german_std[train_index,"Default"])
test_data <- pc_scores[-train_index, ]
test_label <- as.factor(dummy.german_std[-train_index,"Default"])

# Train the KNN classifier using the training data
knn_model <- train(
  x = train_data,
  y = train_label,
  method = "knn",
  trControl = trainControl(method = "cv", number = 10)
)

# Predict the test data using the trained model
knn_pred <- predict(knn_model, newdata = test_data)

# Evaluate the performance of the model
confusionMatrix(model.preds, test_label)
```

